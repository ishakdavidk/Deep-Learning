{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "X = X / 255.\n",
    "\n",
    "# rescale the data, use the traditional train/test split\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.60665357\n",
      "Iteration 2, loss = 0.41250209\n",
      "Iteration 3, loss = 0.41051453\n",
      "Iteration 4, loss = 0.42239682\n",
      "Iteration 5, loss = 0.40242161\n",
      "Iteration 6, loss = 0.41318707\n",
      "Iteration 7, loss = 0.44401505\n",
      "Iteration 8, loss = 0.47749627\n",
      "Iteration 9, loss = 0.46657552\n",
      "Iteration 10, loss = 0.46982848\n",
      "Iteration 11, loss = 0.45269498\n",
      "Iteration 12, loss = 0.45404194\n",
      "Iteration 13, loss = 0.44569686\n",
      "Iteration 14, loss = 0.45222837\n",
      "Iteration 15, loss = 0.52326494\n",
      "Iteration 16, loss = 0.48696374\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      "\n",
      "Training accuracy: 0.881167\n",
      "Test accuracy: 0.878400\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=20, alpha=1e-4,\n",
    "                    solver='adam', verbose=20, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print('\\n')\n",
    "print(\"Training accuracy: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test accuracy: %f\" % mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
