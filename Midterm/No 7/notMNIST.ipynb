{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LeakyReLU, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task A : Read Matlab Data, Divide Data, and Plot Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'images', 'labels'])\n",
      "\n",
      "Images shape :  (18724, 28, 28)\n",
      "Labels shape :  (18724,)\n",
      "\n",
      "After splitting data : \n",
      "Train images shape :  (14043, 28, 28)\n",
      "Train labels shape :  (14043,)\n",
      "Test images shape :  (4681, 28, 28)\n",
      "Test labels shape :  (4681,)\n"
     ]
    }
   ],
   "source": [
    "# Load notMNIST Data\n",
    "notFashion_mnist = loadmat('notMNIST_small')\n",
    "\n",
    "print(notFashion_mnist.keys())\n",
    "\n",
    "X = notFashion_mnist['images']\n",
    "X = X.transpose()\n",
    "print('\\nImages shape : ', X.shape)\n",
    "\n",
    "Y = notFashion_mnist['labels']\n",
    "print('Labels shape : ', Y.shape)\n",
    "\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    X, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "print('\\nAfter splitting data : ')\n",
    "print('Train images shape : ', train_images.shape)\n",
    "print('Train labels shape : ', train_labels.shape)\n",
    "print('Test images shape : ', test_images.shape)\n",
    "print('Test labels shape : ', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First  15   train  images\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First  15   test  images\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def printImages(type, n, X):\n",
    "    print('\\nFirst ', n, ' ', type, ' images')\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(n):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(X[i], cmap=plt.cm.binary)\n",
    "    plt.show()\n",
    "    \n",
    "printImages('train', 15, train_images)\n",
    "printImages('test', 15, test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B : Mean Subtraction and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Pixel Value\n",
      "Train :\n",
      "Min:  0.0  Max:  255.0  Mean:  108.3942622658976  Std:  116.93016352966536\n",
      "Test :\n",
      "Min:  0.0  Max:  255.0  Mean:  108.68820328815141  Std:  117.00370610295343\n"
     ]
    }
   ],
   "source": [
    "# Pixel values\n",
    "train_min = train_images.min()\n",
    "test_min = test_images.min()\n",
    "\n",
    "train_max = train_images.max()\n",
    "test_max = test_images.max()\n",
    "\n",
    "train_mean = train_images.mean()\n",
    "test_mean = test_images.mean()\n",
    "\n",
    "train_std = train_images.std()\n",
    "test_std = test_images.std()\n",
    "\n",
    "print('Original Pixel Value')\n",
    "print('Train :\\nMin: ', train_min, \" Max: \", train_max, \" Mean: \", train_mean, \" Std: \", train_std)\n",
    "print('Test :\\nMin: ', test_min, \" Max: \", test_max, \" Mean: \", test_mean, \" Std: \", test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Subtraction\n",
    "train_images = train_images - train_mean\n",
    "test_images = test_images - test_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "train_images = train_images / train_std\n",
    "test_images = test_images / test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Pixel Value\n",
      "Train :\n",
      "Min:  -0.9270000057632504  Max:  1.2537888711402367  Mean:  2.822625795407159e-17  Std:  1.0000000000000007\n",
      "Test :\n",
      "Min:  -0.9289295776025669  Max:  1.2504885664314471  Mean:  -2.3915132036447703e-17  Std:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Pixel values\n",
    "print('New Pixel Value')\n",
    "print('Train :\\nMin: ', train_images.min(), \" Max: \" ,train_images.max(), \" Mean: \" ,train_images.mean(), \" Std: \" ,train_images.std())\n",
    "print('Test :\\nMin: ', test_images.min(), \" Max: \" ,test_images.max(), \" Mean: \" ,test_images.mean(), \" Std: \" ,test_images.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task C : Xavier and He Initalization Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Xavier Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Laboratory\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 1s 85us/sample - loss: 0.4599 - acc: 0.8698\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 1s 78us/sample - loss: 0.2924 - acc: 0.9150\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 1s 74us/sample - loss: 0.2237 - acc: 0.9327\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 1s 76us/sample - loss: 0.1783 - acc: 0.9464\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 1s 80us/sample - loss: 0.1418 - acc: 0.9571\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 1s 74us/sample - loss: 0.1214 - acc: 0.9640\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 1s 75us/sample - loss: 0.0975 - acc: 0.9705\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 1s 76us/sample - loss: 0.0815 - acc: 0.9762\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 1s 76us/sample - loss: 0.0732 - acc: 0.9786\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 1s 79us/sample - loss: 0.0591 - acc: 0.9823\n",
      "4681/4681 - 0s - loss: 0.4086 - acc: 0.9137\n",
      "\n",
      "Test accuracy: 0.91369367\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - ETA: 0s - loss: 1.4323 - acc: 0.425 - 4s 286us/sample - loss: 1.4295 - acc: 0.4271\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 4s 271us/sample - loss: 0.6983 - acc: 0.7977\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 4s 270us/sample - loss: 0.5672 - acc: 0.8465\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 4s 309us/sample - loss: 0.6186 - acc: 0.8238\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 5s 321us/sample - loss: 0.6002 - acc: 0.8159\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 4s 265us/sample - loss: 0.5405 - acc: 0.8358\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 4s 259us/sample - loss: 0.5166 - acc: 0.8593\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 4s 289us/sample - loss: 0.4521 - acc: 0.8712\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 5s 321us/sample - loss: 0.4333 - acc: 0.8747\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 4s 291us/sample - loss: 0.5525 - acc: 0.8317\n",
      "4681/4681 - 1s - loss: 0.5714 - acc: 0.8280\n",
      "\n",
      "Test accuracy: 0.8280282\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 9s 635us/sample - loss: 0.6430 - acc: 0.8585\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 10s 682us/sample - loss: 0.3480 - acc: 0.9124\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 9s 646us/sample - loss: 0.3008 - acc: 0.9245\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 9s 670us/sample - loss: 0.2982 - acc: 0.9314\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 9s 627us/sample - loss: 0.2939 - acc: 0.9383 0s - loss: 0.2929 - acc: 0.9\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 9s 622us/sample - loss: 0.2437 - acc: 0.9460\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 9s 632us/sample - loss: 0.2315 - acc: 0.9534\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 9s 629us/sample - loss: 0.2576 - acc: 0.9526\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 9s 619us/sample - loss: 0.2184 - acc: 0.9606\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 9s 628us/sample - loss: 0.1692 - acc: 0.96590s - loss: 0.1671 - \n",
      "4681/4681 - 1s - loss: 0.6934 - acc: 0.9145\n",
      "\n",
      "Test accuracy: 0.91454816\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(2560, activation='relu', kernel_initializer='glorot_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**He Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 1s 78us/sample - loss: 0.4758 - acc: 0.8661\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 1s 72us/sample - loss: 0.2865 - acc: 0.9181\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 1s 74us/sample - loss: 0.2204 - acc: 0.9354\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 1s 72us/sample - loss: 0.1790 - acc: 0.9451\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 1s 72us/sample - loss: 0.1385 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 1s 72us/sample - loss: 0.1165 - acc: 0.9647\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.0949 - acc: 0.9715\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 1s 74us/sample - loss: 0.0794 - acc: 0.9768\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 1s 72us/sample - loss: 0.0733 - acc: 0.9771\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 1s 72us/sample - loss: 0.0606 - acc: 0.9815\n",
      "4681/4681 - 0s - loss: 0.4171 - acc: 0.9152\n",
      "\n",
      "Test accuracy: 0.9151891\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 4s 264us/sample - loss: 0.7461 - acc: 0.7707\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 4s 255us/sample - loss: 0.4503 - acc: 0.8745\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 4s 255us/sample - loss: 0.3708 - acc: 0.8933\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 4s 251us/sample - loss: 0.3570 - acc: 0.8994\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 4s 252us/sample - loss: 0.3311 - acc: 0.9064\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 4s 253us/sample - loss: 0.3439 - acc: 0.9032\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 4s 255us/sample - loss: 0.2990 - acc: 0.9099\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 4s 254us/sample - loss: 0.2863 - acc: 0.9142\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 4s 262us/sample - loss: 0.2574 - acc: 0.9230\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 4s 257us/sample - loss: 0.3061 - acc: 0.9096\n",
      "4681/4681 - 0s - loss: 0.4141 - acc: 0.8868\n",
      "\n",
      "Test accuracy: 0.8867763\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 9s 619us/sample - loss: 0.7347 - acc: 0.8556: 2s - l - ETA: 0s - loss: 0.746\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 9s 644us/sample - loss: 0.3597 - acc: 0.9139\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 9s 629us/sample - loss: 0.3134 - acc: 0.9257\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 9s 636us/sample - loss: 0.2810 - acc: 0.9369\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 9s 615us/sample - loss: 0.2716 - acc: 0.9399\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 9s 620us/sample - loss: 0.2609 - acc: 0.9474\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 9s 616us/sample - loss: 0.2678 - acc: 0.9541\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 9s 619us/sample - loss: 0.2093 - acc: 0.9616\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 9s 623us/sample - loss: 0.2177 - acc: 0.9611s - loss:\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 9s 636us/sample - loss: 0.2563 - acc: 0.9585s - loss: 0.235 - ETA: 3s - loss: 0.2449 - acc: 0.958 - ETA: 3s - ETA: 1s - loss: 0.25 - ETA: 0s - loss: 0.2504 -\n",
      "4681/4681 - 1s - loss: 0.9798 - acc: 0.9017\n",
      "\n",
      "Test accuracy: 0.9017304\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(2560, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task D : Network Configuration Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First Model** : Normal Implementation for Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 1s 77us/sample - loss: 0.4766 - acc: 0.8639\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.2963 - acc: 0.9166\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.2303 - acc: 0.9316\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.1833 - acc: 0.9440\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - ETA: 0s - loss: 0.1440 - acc: 0.956 - 1s 73us/sample - loss: 0.1445 - acc: 0.9559\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 1s 75us/sample - loss: 0.1158 - acc: 0.9645\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 1s 77us/sample - loss: 0.0974 - acc: 0.9710\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 1s 74us/sample - loss: 0.0840 - acc: 0.9752\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 1s 72us/sample - loss: 0.0753 - acc: 0.9763\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.0601 - acc: 0.9830\n",
      "4681/4681 - 0s - loss: 0.4642 - acc: 0.9071\n",
      "\n",
      "Test accuracy: 0.9070711\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second Model** : Large Number of Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 415,498\n",
      "Trainable params: 415,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 4s 269us/sample - loss: 1.1234 - acc: 0.5616\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 4s 259us/sample - loss: 0.5584 - acc: 0.8355\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 4s 255us/sample - loss: 0.5025 - acc: 0.8480\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 4s 256us/sample - loss: 0.3789 - acc: 0.8863\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 4s 259us/sample - loss: 0.4316 - acc: 0.8729\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 4s 256us/sample - loss: 0.4118 - acc: 0.8830\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 4s 259us/sample - loss: 0.3214 - acc: 0.9084\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 4s 258us/sample - loss: 0.2844 - acc: 0.9155\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 4s 291us/sample - loss: 0.3745 - acc: 0.8877\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 4s 274us/sample - loss: 0.3810 - acc: 0.8886\n",
      "4681/4681 - 0s - loss: 0.4136 - acc: 0.8787\n",
      "\n",
      "Test accuracy: 0.8786584\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Third Model** : Large number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2560)              2009600   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                25610     \n",
      "=================================================================\n",
      "Total params: 2,035,210\n",
      "Trainable params: 2,035,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(2560, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 9s 635us/sample - loss: 0.6387 - acc: 0.8622\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 9s 633us/sample - loss: 0.3560 - acc: 0.9103\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 9s 624us/sample - loss: 0.3376 - acc: 0.9223\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 9s 636us/sample - loss: 0.2715 - acc: 0.9342s - loss: 0.2621 - ac - ETA: 2s - - ETA: 0s - loss: 0.2738 - acc\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 9s 628us/sample - loss: 0.2819 - acc: 0.9382s - - ETA: 3s \n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 9s 652us/sample - loss: 0.2423 - acc: 0.9477\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 9s 652us/sample - loss: 0.2391 - acc: 0.9544\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 9s 636us/sample - loss: 0.2268 - acc: 0.9571\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 9s 642us/sample - loss: 0.2209 - acc: 0.9588s - lo\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 9s 639us/sample - loss: 0.1991 - acc: 0.9629\n",
      "4681/4681 - 1s - loss: 0.8563 - acc: 0.9081\n",
      "\n",
      "Test accuracy: 0.9081393\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task E : Gradient Optimization Techniques Experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 1s 78us/sample - loss: 0.4742 - acc: 0.8695\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.2895 - acc: 0.9164\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.2215 - acc: 0.9353\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 1s 74us/sample - loss: 0.1779 - acc: 0.9465\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 1s 75us/sample - loss: 0.1391 - acc: 0.9578\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 1s 75us/sample - loss: 0.1214 - acc: 0.9635\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 1s 76us/sample - loss: 0.0934 - acc: 0.9734\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 1s 75us/sample - loss: 0.0824 - acc: 0.9746\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 1s 74us/sample - loss: 0.0647 - acc: 0.9809\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.0601 - acc: 0.9821\n",
      "4681/4681 - 0s - loss: 0.4366 - acc: 0.9049\n",
      "\n",
      "Test accuracy: 0.9049348\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 4s 268us/sample - loss: 1.4196 - acc: 0.4244\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 4s 258us/sample - loss: 0.7049 - acc: 0.7911\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 4s 255us/sample - loss: 0.5382 - acc: 0.8513\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 4s 257us/sample - loss: 0.4164 - acc: 0.8817\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 4s 253us/sample - loss: 0.3861 - acc: 0.8898\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 4s 254us/sample - loss: 0.4138 - acc: 0.8810\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 4s 253us/sample - loss: 0.3825 - acc: 0.8945\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 4s 258us/sample - loss: 0.5088 - acc: 0.8462\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 4s 256us/sample - loss: 0.6708 - acc: 0.7701\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 4s 257us/sample - loss: 0.8142 - acc: 0.7632\n",
      "4681/4681 - 0s - loss: 0.7785 - acc: 0.7633\n",
      "\n",
      "Test accuracy: 0.76329845\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 9s 640us/sample - loss: 0.6288 - acc: 0.8662s - loss: 1. -  - ETA: 0s - loss: 0.6338 - acc: 0.8\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 9s 624us/sample - loss: 0.3748 - acc: 0.9103s - loss: 0.3761\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 9s 632us/sample - loss: 0.3169 - acc: 0.9227\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 9s 671us/sample - loss: 0.2848 - acc: 0.9333s - loss: 0.2748 - a\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 9s 647us/sample - loss: 0.2901 - acc: 0.9378\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 9s 642us/sample - loss: 0.2537 - acc: 0.9464\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 9s 629us/sample - loss: 0.2297 - acc: 0.9534s - \n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 9s 631us/sample - loss: 0.2416 - acc: 0.9546\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 9s 631us/sample - loss: 0.2634 - acc: 0.9529\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 9s 638us/sample - loss: 0.1524 - acc: 0.9699\n",
      "4681/4681 - 1s - loss: 0.8102 - acc: 0.8876\n",
      "\n",
      "Test accuracy: 0.8876308\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(2560, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSprop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 1s 92us/sample - loss: 0.4658 - acc: 0.8708\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 1s 85us/sample - loss: 0.3021 - acc: 0.9153\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 1s 85us/sample - loss: 0.2342 - acc: 0.9323\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 1s 85us/sample - loss: 0.1886 - acc: 0.9447\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 1s 88us/sample - loss: 0.1466 - acc: 0.9559\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 1s 84us/sample - loss: 0.1225 - acc: 0.9622\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 1s 85us/sample - loss: 0.1027 - acc: 0.9688\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 1s 85us/sample - loss: 0.0807 - acc: 0.9756\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 1s 87us/sample - loss: 0.0718 - acc: 0.9789\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 1s 86us/sample - loss: 0.0618 - acc: 0.9816\n",
      "4681/4681 - 0s - loss: 0.4809 - acc: 0.9092\n",
      "\n",
      "Test accuracy: 0.90920746\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 4s 307us/sample - loss: 1.1945 - acc: 0.5425\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 4s 278us/sample - loss: 0.5889 - acc: 0.8318\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 4s 278us/sample - loss: 0.4459 - acc: 0.8746\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 4s 284us/sample - loss: 0.3853 - acc: 0.8933\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 4s 277us/sample - loss: 0.3674 - acc: 0.8965\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 4s 281us/sample - loss: 0.3359 - acc: 0.9088\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 4s 279us/sample - loss: 0.3327 - acc: 0.9091\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 4s 278us/sample - loss: 0.3394 - acc: 0.9098\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 4s 278us/sample - loss: 0.3246 - acc: 0.9118\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 4s 278us/sample - loss: 0.3242 - acc: 0.9135\n",
      "4681/4681 - 0s - loss: 0.6208 - acc: 0.9049\n",
      "\n",
      "Test accuracy: 0.9049348\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 15s 1ms/sample - loss: 0.7747 - acc: 0.8530\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 15s 1ms/sample - loss: 0.4603 - acc: 0.9003\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 15s 1ms/sample - loss: 0.3516 - acc: 0.9235\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 15s 1ms/sample - loss: 0.3025 - acc: 0.9360\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 15s 1ms/sample - loss: 0.2562 - acc: 0.9478\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 15s 1ms/sample - loss: 0.2293 - acc: 0.9564\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 15s 1ms/sample - loss: 0.2165 - acc: 0.9596\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 15s 1ms/sample - loss: 0.1773 - acc: 0.9671\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 15s 1ms/sample - loss: 0.1736 - acc: 0.9682\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 15s 1ms/sample - loss: 0.1676 - acc: 0.9712\n",
      "4681/4681 - 1s - loss: 0.8687 - acc: 0.9101\n",
      "\n",
      "Test accuracy: 0.91006196\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(2560, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task F : Activation Functions Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ReLU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 1s 79us/sample - loss: 0.4600 - acc: 0.8697\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.2844 - acc: 0.9177\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 1s 72us/sample - loss: 0.2190 - acc: 0.9346\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.1755 - acc: 0.9477\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 1s 72us/sample - loss: 0.1421 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 1s 78us/sample - loss: 0.1150 - acc: 0.9654\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.0940 - acc: 0.9724\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 1s 72us/sample - loss: 0.0886 - acc: 0.9716\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 1s 72us/sample - loss: 0.0704 - acc: 0.9794\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.0666 - acc: 0.9793\n",
      "4681/4681 - 0s - loss: 0.4247 - acc: 0.9101\n",
      "\n",
      "Test accuracy: 0.91006196\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 4s 269us/sample - loss: 1.3730 - acc: 0.4534\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 4s 258us/sample - loss: 0.8577 - acc: 0.7269\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 4s 254us/sample - loss: 0.5836 - acc: 0.8371\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 4s 257us/sample - loss: 0.5573 - acc: 0.8473\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 4s 268us/sample - loss: 0.4524 - acc: 0.8732\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 4s 254us/sample - loss: 0.4305 - acc: 0.8798\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 4s 258us/sample - loss: 0.4760 - acc: 0.8638\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 4s 253us/sample - loss: 0.4832 - acc: 0.8616\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 4s 256us/sample - loss: 0.5026 - acc: 0.8554\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 4s 261us/sample - loss: 0.5239 - acc: 0.8453\n",
      "4681/4681 - 1s - loss: 0.5091 - acc: 0.8505\n",
      "\n",
      "Test accuracy: 0.8504593\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 9s 650us/sample - loss: 0.6348 - acc: 0.8612\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 9s 658us/sample - loss: 0.3678 - acc: 0.9093\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 9s 648us/sample - loss: 0.3284 - acc: 0.9196\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 9s 648us/sample - loss: 0.2945 - acc: 0.9310\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 9s 658us/sample - loss: 0.2630 - acc: 0.9416\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 9s 651us/sample - loss: 0.2649 - acc: 0.9434\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 9s 651us/sample - loss: 0.2346 - acc: 0.9506\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 9s 648us/sample - loss: 0.2411 - acc: 0.9563\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 9s 669us/sample - loss: 0.1677 - acc: 0.9672\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 9s 663us/sample - loss: 0.1874 - acc: 0.9662\n",
      "4681/4681 - 1s - loss: 0.7939 - acc: 0.9069\n",
      "\n",
      "Test accuracy: 0.9068575\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(2560, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Leaky ReLU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 1s 78us/sample - loss: 0.5071 - acc: 0.8601\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.3560 - acc: 0.9014\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 1s 74us/sample - loss: 0.2922 - acc: 0.9155\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 1s 75us/sample - loss: 0.2520 - acc: 0.9278\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 1s 74us/sample - loss: 0.2228 - acc: 0.9346\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 1s 75us/sample - loss: 0.1977 - acc: 0.9405\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 1s 75us/sample - loss: 0.1792 - acc: 0.9452\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 1s 74us/sample - loss: 0.1576 - acc: 0.9526\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 1s 75us/sample - loss: 0.1414 - acc: 0.9568\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 1s 74us/sample - loss: 0.1176 - acc: 0.9645\n",
      "4681/4681 - 0s - loss: 0.4184 - acc: 0.9051\n",
      "\n",
      "Test accuracy: 0.90514845\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 4s 288us/sample - loss: 0.8118 - acc: 0.7174\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 4s 274us/sample - loss: 0.5178 - acc: 0.8478\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 4s 275us/sample - loss: 0.4263 - acc: 0.8853\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 4s 275us/sample - loss: 0.3843 - acc: 0.8957\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 4s 274us/sample - loss: 0.3489 - acc: 0.9034\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 4s 290us/sample - loss: 0.3507 - acc: 0.9025\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 4s 275us/sample - loss: 0.3665 - acc: 0.9000\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 4s 285us/sample - loss: 0.3421 - acc: 0.9058\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 4s 278us/sample - loss: 0.3308 - acc: 0.9098\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 4s 278us/sample - loss: 0.2943 - acc: 0.9145\n",
      "4681/4681 - 1s - loss: 0.5215 - acc: 0.8596\n",
      "\n",
      "Test accuracy: 0.85964537\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 9s 653us/sample - loss: 0.7313 - acc: 0.8477\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 9s 655us/sample - loss: 0.4315 - acc: 0.8849s - loss: 0.4338 - a\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 9s 676us/sample - loss: 0.3996 - acc: 0.8960\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 9s 665us/sample - loss: 0.3638 - acc: 0.9014\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 9s 663us/sample - loss: 0.3487 - acc: 0.9111\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 9s 659us/sample - loss: 0.3269 - acc: 0.9148\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 9s 661us/sample - loss: 0.2991 - acc: 0.9207\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 9s 658us/sample - loss: 0.2974 - acc: 0.9212\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 9s 666us/sample - loss: 0.2521 - acc: 0.9319\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 9s 663us/sample - loss: 0.2576 - acc: 0.9344s - loss: 0.2568 - acc: 0.934\n",
      "4681/4681 - 1s - loss: 0.5948 - acc: 0.8934\n",
      "\n",
      "Test accuracy: 0.8933988\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(2560))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task G : Regularization Techniques Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 1s 89us/sample - loss: 0.6739 - acc: 0.8154\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 1s 82us/sample - loss: 0.4684 - acc: 0.8745\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 1s 84us/sample - loss: 0.4065 - acc: 0.8883\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 1s 86us/sample - loss: 0.3775 - acc: 0.8920\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 1s 81us/sample - loss: 0.3445 - acc: 0.8996\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 1s 81us/sample - loss: 0.3370 - acc: 0.9057\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 1s 81us/sample - loss: 0.3183 - acc: 0.9088\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 1s 81us/sample - loss: 0.3021 - acc: 0.9104\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 1s 81us/sample - loss: 0.2944 - acc: 0.9135\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 1s 81us/sample - loss: 0.2836 - acc: 0.9158\n",
      "4681/4681 - 0s - loss: 0.3282 - acc: 0.9141\n",
      "\n",
      "Test accuracy: 0.9141209\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 4s 258us/sample - loss: 2.2925 - acc: 0.1337\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 3s 238us/sample - loss: 2.0221 - acc: 0.2056\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 3s 240us/sample - loss: 1.8828 - acc: 0.2252\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 3s 238us/sample - loss: 1.8168 - acc: 0.2456\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 3s 238us/sample - loss: 1.7825 - acc: 0.2695\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 3s 241us/sample - loss: 1.7565 - acc: 0.2816\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 3s 249us/sample - loss: 1.6922 - acc: 0.3117\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 3s 240us/sample - loss: 1.6602 - acc: 0.3251\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 3s 241us/sample - loss: 1.6291 - acc: 0.3330\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 3s 241us/sample - loss: 1.6041 - acc: 0.3333\n",
      "4681/4681 - 0s - loss: 3.0179 - acc: 0.1045\n",
      "\n",
      "Test accuracy: 0.10446486\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 5s 360us/sample - loss: 0.7205 - acc: 0.8396\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 5s 355us/sample - loss: 0.5325 - acc: 0.8777\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 5s 360us/sample - loss: 0.4465 - acc: 0.8990\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 5s 357us/sample - loss: 0.4487 - acc: 0.9031\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 5s 358us/sample - loss: 0.4276 - acc: 0.9051\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 5s 360us/sample - loss: 0.4234 - acc: 0.9126\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 5s 362us/sample - loss: 0.4015 - acc: 0.9185\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 5s 361us/sample - loss: 0.4011 - acc: 0.9204\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 5s 360us/sample - loss: 0.3936 - acc: 0.9275\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 5s 363us/sample - loss: 0.3800 - acc: 0.9286\n",
      "4681/4681 - 1s - loss: 0.6435 - acc: 0.9075\n",
      "\n",
      "Test accuracy: 0.9074984\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(1280, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 1s 80us/sample - loss: 0.8814 - acc: 0.8661\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.6017 - acc: 0.9107\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.5006 - acc: 0.9283\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 1s 79us/sample - loss: 0.4429 - acc: 0.9371\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 1s 75us/sample - loss: 0.3987 - acc: 0.9471\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 1s 74us/sample - loss: 0.3616 - acc: 0.9535\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.3339 - acc: 0.9596\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.3292 - acc: 0.9596\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.2878 - acc: 0.9693\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 1s 73us/sample - loss: 0.2727 - acc: 0.9714\n",
      "4681/4681 - 0s - loss: 0.5539 - acc: 0.9024\n",
      "\n",
      "Test accuracy: 0.9023713\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 3s 190us/sample - loss: 2.3708 - acc: 0.1016\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 2s 174us/sample - loss: 2.3147 - acc: 0.1015\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 2s 177us/sample - loss: 2.3072 - acc: 0.1001\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 2s 174us/sample - loss: 2.3048 - acc: 0.1007\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 2s 174us/sample - loss: 2.3038 - acc: 0.0957\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 2s 173us/sample - loss: 2.3036 - acc: 0.0996\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 2s 176us/sample - loss: 2.3033 - acc: 0.1007\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 2s 176us/sample - loss: 2.3034 - acc: 0.1005\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 2s 176us/sample - loss: 2.3033 - acc: 0.0995\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 2s 174us/sample - loss: 2.3033 - acc: 0.1008\n",
      "4681/4681 - 0s - loss: 2.3036 - acc: 0.0934\n",
      "\n",
      "Test accuracy: 0.09335612\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14043 samples\n",
      "Epoch 1/10\n",
      "14043/14043 [==============================] - 5s 342us/sample - loss: 1.3880 - acc: 0.8728\n",
      "Epoch 2/10\n",
      "14043/14043 [==============================] - 5s 338us/sample - loss: 0.7455 - acc: 0.9091\n",
      "Epoch 3/10\n",
      "14043/14043 [==============================] - 5s 337us/sample - loss: 0.5795 - acc: 0.9269\n",
      "Epoch 4/10\n",
      "14043/14043 [==============================] - 5s 334us/sample - loss: 0.4863 - acc: 0.9375\n",
      "Epoch 5/10\n",
      "14043/14043 [==============================] - 5s 334us/sample - loss: 0.4294 - acc: 0.9492\n",
      "Epoch 6/10\n",
      "14043/14043 [==============================] - 5s 335us/sample - loss: 0.3886 - acc: 0.9549\n",
      "Epoch 7/10\n",
      "14043/14043 [==============================] - 5s 344us/sample - loss: 0.3636 - acc: 0.9603\n",
      "Epoch 8/10\n",
      "14043/14043 [==============================] - 5s 337us/sample - loss: 0.3495 - acc: 0.9638\n",
      "Epoch 9/10\n",
      "14043/14043 [==============================] - 5s 345us/sample - loss: 0.3468 - acc: 0.9665\n",
      "Epoch 10/10\n",
      "14043/14043 [==============================] - 5s 334us/sample - loss: 0.3118 - acc: 0.9699\n",
      "4681/4681 - 1s - loss: 0.5701 - acc: 0.9047\n",
      "\n",
      "Test accuracy: 0.9047212\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(1280, activation='relu', activity_regularizer=keras.regularizers.l1(0.01)))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
